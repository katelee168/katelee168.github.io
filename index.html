<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc-markdown-css-theme" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Katherine Lee</title>
  <link rel="stylesheet" href="css/theme.css" />
  <link rel="stylesheet" href="css/skylighting-paper-theme.css" />
  <link rel="stylesheet" href="css/theme-additions.css" />
<!-- Personal -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-165430430-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-165430430-1');
</script>
</head>
<body>

<header>
  <h1 class="title">Katherine Lee</h1>
<div class="metadata">

</div>

</header>

<nav id="TOC" role="doc-toc">
    <input type="checkbox" id="contents">
  <label for="contents">
    <h4 id="toc-heading">
              Contents
            <svg id="toc-chevron" width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M2.08926 3.16074C1.76382 2.83531 1.23618 2.83531 0.910744 3.16074C0.585307 3.48618 0.585307 4.01382 0.910744 4.33926L2.08926 3.16074ZM6 8.25L5.41074 8.83926C5.73618 9.16469 6.26382 9.16469 6.58926 8.83926L6 8.25ZM11.0893 4.33926C11.4147 4.01382 11.4147 3.48618 11.0893 3.16074C10.7638 2.83531 10.2362 2.83531 9.91074 3.16074L11.0893 4.33926ZM0.910744 4.33926L5.41074 8.83926L6.58926 7.66074L2.08926 3.16074L0.910744 4.33926ZM6.58926 8.83926L11.0893 4.33926L9.91074 3.16074L5.41074 7.66074L6.58926 8.83926Z" fill="currentColor"/>
      </svg>
    </h4>
  </label>
  <ul>
  <li><a href="#selected-publications" id="toc-selected-publications">Selected Publications</a></li>
  <li><a href="#writing" id="toc-writing">Writing</a>
  <ul>
  <li><a href="#fun-writing" id="toc-fun-writing">Fun writing</a></li>
  </ul></li>
  <li><a href="#invited-talks" id="toc-invited-talks">Invited Talks</a></li>
  <li><a href="#fun" id="toc-fun">Fun!</a></li>
  </ul>
</nav>


<main id="main" class="">
  <!-- <p align="left"><sup>(she/her)</sup></p>
<div><img style="padding: 25px" src="images/me.jpeg" width="200" border="50" align="right"/></div>
<div style="text-align: justify">Hello!  -->
<p><img class="avatar" alt="Katherine Lee" src="./images/katherine-300x300.jpg"></p>
<p>I’m currently a staff research scientist at Google DeepMind and run the <a href="https://genlaw.org">GenLaw Center</a>. I study security and privacy in generative AI models and the legal implications those have. Specifically, I evaluate data extraction (memorization) in generative AI models and attacks (mis-aligning) for generative AI models.</p>
<p>Broadly, I’m interested in building machine learning systems we can trust. This means figuring out when models are untrustworthy and creating or discovering knobs to change their behavior.</p>
<p>You can find me on the internet: <a href="https://scholar.google.com/citations?user=bjdB4K8AAAAJ&amp;hl=en">Google Scholar</a>, <a href="https://www.goodreads.com/user/show/44386744-katherine">Goodreads</a>, or email me at [my github handle] @ gmail.com</p>
<dl>
<dt>If you need a bio for a talk, please use this one:</dt>
<dd>
Katherine is a staff research scientist at Google DeepMind. Her work has provided essential empirical evidence and measurement for grounding discussions around concerns that language models infringe copyright, and about how language models can respect an individuals’ right to privacy and control of their data. Additionally, she has developed large language models (T5), developed methods of reducing memorization, and studied the impact of data curation on model development. Her work has been highly awarded at venues like: ACL, USENIX, and ICLR.
</dd>
</dl>
</div>
<h2 id="selected-publications">Selected Publications</h2>
<blockquote>
<p>Full list on <a href="https://scholar.google.com/citations?user=bjdB4K8AAAAJ&amp;hl=en">Google Scholar</a></p>
</blockquote>
<dl>
<dt>T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer [<a href="https://www.jmlr.org/papers/volume21/20-074/20-074.pdf">JMLR</a>]<br/></dt>
<dd>
<a href="https://colinraffel.com/">Colin Raffel</a>*, Noam Shazeer*, Adam Roberts*, <strong>Katherine Lee</strong>*, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. June, 2020
</dd>
<dt>Extracting Training Data from Large Language Models [<a href="https://arxiv.org/abs/2012.07805">arxiv</a>] [<a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting">USENIX Oral</a>][<a href="https://bair.berkeley.edu/blog/2020/12/20/lmmem/">blog</a>] [<a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting">video</a>]<br/></dt>
<dd>
<a href="https://nicholas.carlini.com/">Nicholas Carlini</a>, <a href="https://floriantramer.com/">Florian Tramèr</a>, <a href="https://www.ericswallace.com/">Eric Wallace</a>, <a href="https://jagielski.github.io/">Matthew Jagielski</a>, Ariel Herbert-Voss, <strong>Katherine Lee</strong>, <a href="https://research.google/people/104881/">Adam Roberts</a>, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, <a href="https://colinraffel.com/">Colin Raffel</a>. Dec, 2020
</dd>
<dd>
runner up <a href="https://petsymposium.org/award/winners.php">Caspar Bowden award at PETS 2023</a>
</dd>
<dt>Extracting Training Data from ChatGPT [<a href="https://arxiv.org/abs/2311.17035">arxiv</a>][<a href="https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html">blog</a>]<br/></dt>
<dd>
<a href="https://srxzr.com/">Milad Nasr*</a>, <a href="https://nicholas.carlini.com/">Nicholas Carlini*</a>, <a href="https://jhayase.github.io/">Jon Hayase</a>, <a href="https://jagielski.github.io/">Matthew Jagielski</a>, <a href="https://afedercooper.info/">A. Feder Cooper</a>, <a href="https://daphnei.com/">Daphne Ippolito</a>, <a href="https://www.christopherchoquette.com/">Christopher A. Choquette-Choo</a>, <a href="https://ericswallace.com/">Eric Wallace</a>, <a href="https://www.floriantramer.com/">Florian Tramèr</a>, <strong>Katherine Lee</strong>. Nov 2023
</dd>
<dt>Deduplicating Training Data Makes Language Models Better [<a href="https://arxiv.org/abs/2107.06499">arxiv</a>] [<a href="https://aclanthology.org/2022.acl-long.577/">ACL Oral</a>]</dt>
<dd>
<strong>Katherine Lee</strong>*, <a href="https://www.seas.upenn.edu/~daphnei/me/category/about-me.html">Daphne Ippolito</a>*, Andrew Nystrom, <a href="https://pluskid.org/">Chiyuan Zhang</a>, <a href="https://research.google/people/author39086/">Douglas Eck</a>, <a href="https://www.cis.upenn.edu/~ccb/">Chris Callison-Burch</a>, <a href="https://nicholas.carlini.com/">Nicholas Carlini</a>. July 2021
</dd>
<dt>Quantifying Memorization Across Neural Language Models [<a href="https://arxiv.org/abs/2202.07646">arxiv</a>][ICLR Spotlight]<br/></dt>
<dd>
<a href="https://nicholas.carlini.com/">Nicholas Carlini</a>*, <a href="https://www.seas.upenn.edu/~daphnei/me/category/about-me.html">Daphne Ippolito</a>*, <a href="https://jagielski.github.io/">Matthew Jagielski</a>*, <strong>Katherine Lee*</strong>, <a href="https://floriantramer.com/">Florian Tramèr</a>*, <a href="https://pluskid.org/">Chiyuan Zhang</a>*. Feb 2022 (*authors alphabetical)
</dd>
<dt>What Does it Mean for a Language Model to Preserve Privacy? [<a href="https://arxiv.org/abs/2202.05520">arxiv</a>][<a href="https://dl.acm.org/doi/fullHtml/10.1145/3531146.3534642">FAccT</a>]<br/></dt>
<dd>
Hannah Brown, <strong>Katherine Lee</strong>, <a href="https://cseweb.ucsd.edu/~fmireshg/">Fatemehsadat Mireshghalla</a>, <a href="https://www.comp.nus.edu.sg/~reza/">Reza Shokri</a>, <a href="https://floriantramer.com/">Florian Tramèr</a>. Feb 2022
</dd>
</dl>
<!-- Measuring Forgetting of Memorized Training Examples [[arxiv](https://arxiv.org/abs/2207.00099)][ICLR]<br/>: [Matthew Jagielski](https://jagielski.github.io/), [Om Thakkar](http://www.omthakkar.com/), [Florian Tramèr](https://floriantramer.com/), [Daphne Ippolito](https://www.seas.upenn.edu/~daphnei/me/category/about-me.html), **Katherine Lee**, [Nicholas Carlini](https://nicholas.carlini.com/), [Eric Wallace](https://www.ericswallace.com/), [Shuang Song](https://shs037.github.io/), Abhradeep Thakurta, [Nicolas Papernot](https://www.papernot.fr/), [Chiyuan Zhang](https://pluskid.org/). Jun 2022 -->
<!-- Counterfactual Memorization in Neural Language Models [[arxiv](https://arxiv.org/abs/2112.12938)]<br/>: [Chiyuan Zhang](https://pluskid.org/), [Daphne Ippolito](https://www.seas.upenn.edu/~daphnei/me/category/about-me.html), **Katherine Lee**, [Matthew Jagielski](https://jagielski.github.io/), [Florian Tramèr](https://floriantramer.com/), [Nicholas Carlini](https://nicholas.carlini.com/). December 2021 -->
<!-- WT5?! Training Text-to-Text Models to Explain their Predictions [[arxiv](https://arxiv.org/abs/2004.14546)]<br/>: Sharan Narang, [Colin Raffel](https://colinraffel.com/), **Katherine Lee**, Adam Roberts, Noah Fiedel, Karishma Malkan. April, 2020
 -->
<dl>
<dt>Hallucinations in Neural Machine Translation [<a href="https://openreview.net/references/pdf?id=B1Muak8L4">NeurIPS IRASL</a>] <br/></dt>
<dd>
<strong>Katherine Lee</strong>, Orhan Firat, Ashish Agarwal, Clara Fannjiang, and David Sussillo. Dec, 2018
</dd>
</dl>
<!-- Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification [[arxiv](https://arxiv.org/abs/2301.11562)][[pdf](https://katelee168.github.io/pdfs/arbitrary.pdf)]: [A. Feder Cooper](https://afedercooper.info/), **Katherine Lee**, Madiha Zahrah Choksi, Solon Barocas, Christopher De Sa, James Grimmelmann, Jon Kleinberg, Siddhartha Sen, Baobao Zhang. Jan, 2023 -->
<dl>
<dt>Talkin’ ’Bout AI Generation: Copyright and the Generative-AI Supply Chain [<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551">ssrn</a>] [<a href="https://arxiv.org/abs/2309.08133">arxiv</a>][<a href="https://genlaw.org/explainers/talkin.html">blog</a>]<br/></dt>
<dd>
<strong>Katherine Lee</strong>, <a href="https://afedercooper.info/">A. Feder Cooper</a>, <a href="http://james.grimmelmann.net/">James Grimmelmann</a>
</dd>
</dl>
<!-- Propagation of information along the cortical hierarchy as a function of attention while reading and listening to stories [[Cerebral Cortex](https://www.biorxiv.org/content/biorxiv/early/2018/04/08/291526.full.pdf)] <br/>: Mor Regev, Erez Simony, **Katherine Lee**, Kean Ming Tan, Janice Chen, Uri Hasson. Sep, 2019 -->
<h2 id="writing">Writing</h2>
<dl>
<dt><a href="https://genlaw.org/explainers/">AI and Law: The Next Generation</a> (2023)</dt>
<dd>
<a href="https://genlaw.org/explainers/training-data.html">The Devil is in the Training Data</a> (2023)
</dd>
</dl>
<p><a href="https://genlaw.org/explainers/talkin.html">Talkin’ ’Bout AI Generation: Copyright and the Generative-AI Supply Chain</a> (2023)</p>
<p><a href="https://craffel.github.io/blog/writing-a-google-ai-residency-cover-letter.html">Writing a Google AI Residency Cover letter</a> with <a href="https://ben-eysenbach.github.io/">Ben Eysenbach</a> (2019)</p>
<p><a href="blog/submit-to-journals.html">Submit to Journals</a> [<a href="blog/submit-to-journals.pdf">pdf</a>] (2018)</p>
<h3 id="fun-writing">Fun writing</h3>
<p><a href="blog/sourdough.html">Sourdough Literature Review</a> (2020)</p>
<h2 id="invited-talks">Invited Talks</h2>
<dl>
<dt>Security and Privacy</dt>
<dd>
Panel on Machine Learning, Memorization, and Privacy at <a href="https://tpdp.journalprivacyconfidentiality.org/2023/">Theory and Practice of Differential Privacy (TPDP)</a>, Sep 2023
</dd>
<dd>
<a href="https://www.prosus.com/">Prosus</a> AI Marketplace, Oct 2023
</dd>
<dd>
Red Teaming Language Models at <a href="https://www.cmu.edu/block-center/news-events/feb-23-kl-gates-event.html">Supporting NIST’s Development of Guidelines on Red-teaming for Generative AI</a>, Feb 2024 [<a href="pdfs/red-teaming-feb-2024.pdf">slides</a>]
</dd>
<dd>
Why do we care about privacy? at <a href="https://ppai-workshop.github.io/">PPAI</a>, Feb 2024 [<a href="pdfs/why-privacy-feb-2024.pdf">slides</a>]
</dd>
<dt>Generative AI + Law</dt>
<dd>
Copyright Panel at <a href="https://genlaw.org/">Generative AI + Law Workshop @ ICML</a>, Jul 2023
</dd>
<dd>
The Copyright Law of Generative AI at <a href="https://siliconflatirons.org/events/2023-10-06-generative-ai-and-copyright/">Silicon Flatirons Generative AI and Copyright Conference</a>, Oct 2023
</dd>
<dd>
Berkeley <a href="https://www2.eecs.berkeley.edu/Courses/CS188/">CS 188.</a> Introduction to Artificial Intelligence, Dec 2023
</dd>
<dd>
<a href="https://computersciencelaw.org/2024-2/program/">CS + Law</a>, Mar 2024
</dd>
<dt>Memorization in Language Models [<a href="https://katelee168.github.io/pdfs/privacy-slides-dec-2022.pdf">slides</a>] [<a href="https://katelee168.github.io/pdfs/aies-poster-2022.pdf">poster</a>][last updated: Dec 2022]</dt>
<dd>
University of Toronto, May 2022
</dd>
<dd>
<a href="https://www.mosaicml.com/">Mosaic ML</a>, Jul 2022
</dd>
<dd>
GovAI, Aug 2022
</dd>
<dd>
<a href="https://vsehwag.github.io/SPML_seminar/">ML Security &amp; Privacy Seminar</a>, Aug 2022
</dd>
<dd>
<a href="https://www.legalityattentivedatascientists.eu/">LEgally Attentive Data Scientists</a>, Sep 2022
</dd>
<dd>
Cornell, NLP Seminar, Sep 2022
</dd>
<dd>
<a href="https://c-psyd.github.io/">Cornell, C-Psyd</a>, Sep, 2022
</dd>
<dt>What does Privacy in Language Modeling Mean? [<a href="https://katelee168.github.io/pdfs/lm-privacy-slides.pdf">slides</a>]</dt>
<dd>
UNC, Apr 2022
</dd>
<dd>
Cornell, Apr 2022
</dd>
<dt>Dataset selection</dt>
<dd>
<a href="https://www.mosaicml.com/">Mosaic ML</a>, Sep 2023
</dd>
</dl>
<!-- ## Service
* Organized the Generative AI and Law Workshop ([GenLaw '23'](https://genlaw.org/)) at ICML 2023.
* Helped organize [WELM workshop](https://welmworkshop.github.io/) at ICLR 2021 and moderated a panel discussion on "Bias, safety, copyright, and efficiency"
* Reviewer for NeurIPS, ICML. -->
<h2 id="fun">Fun!</h2>
<p>In my free time, I enjoy making stuff. Sometimes this is <a href="https://www.instagram.com/paw_projects/">pottery</a>, <a href="https://www.instagram.com/nomnomnom.s/">sourdough</a>, or knitting/crocheting. I also enjoy being outdoors, listening to <a href="https://open.spotify.com/playlist/37i9dQZF1DX4wta20PHgwo?si=mkKIGDzISB61q_tBGndEiw">jazz</a>, and dancing. Sometimes all at the same time! I used to live <a href="https://ludwigschubert.github.io/twotwelve.house/">here</a>.</p>
<p>During my undergrad in Operations Research at Princeton, I had great fun learning about how real neural networks (brains!) take in the world with <a href="https://pillowlab.princeton.edu/">Jonathan Pillow</a> and <a href="https://www.hassonlab.com/">Uri Hasson</a>.</p>
<p>In the more distant past, I’ve also solved for optimal seating arrangements at Google, and I spotted ships at bay with hyperspectral sensors at the Naval Research Lab in DC.</p>
<hr />
<footer>
<div style="float:left; width: 80%;">
<p>Website generated with <a href="https://pandoc.org">Pandoc</a>, <a href="https://gist.github.com/killercup/5917178">pandoc.css</a>, and help from <a href="https://schubert.io/">Ludwig Schubert</a>.<br />
^ It’s super easy to use and flexible, and you should use it too!</p>
</div>
<div style="float:left; width: 20%; text-align:center;">

</div>
</footer>
</main>


<script>
document.addEventListener("DOMContentLoaded", function () {
    // Non-essential if user has JavaScript off. Just hides TOC button on scroll.
    const nav = document.querySelector("nav");
    let lastScrollTop = 0;
    const min_diff_px = 32;
    
    function didScroll() {
        const currentScrollTop = window.pageYOffset || document.documentElement.scrollTop;
        if (currentScrollTop < lastScrollTop) {
            nav.classList.add("scrolled-up");
            nav.classList.remove("scrolled-down");
            lastScrollTop = currentScrollTop;
        } else if (currentScrollTop > lastScrollTop + min_diff_px) {
            nav.classList.remove("scrolled-up");
            nav.classList.add("scrolled-down");
            lastScrollTop = currentScrollTop;
        }
    }

    window.addEventListener("scroll", didScroll);
});
  
document.addEventListener("DOMContentLoaded", function () {
    const headings = document.querySelectorAll('main h1, main h2, main h3, main h4');

    function handleIntersection(entries) {
        //  IntersectionObserver's entries are ordered by their position in the DOM tree
        const topmostEntry = entries.find(entry => entry.isIntersecting);
        console.log(topmostEntry)
        if (!topmostEntry) return;

        const tocElementId = 'toc-' + topmostEntry.target.id;
        const tocElement = document.getElementById(tocElementId);
        if (!tocElement) return;

        const otherTocElements = document.querySelectorAll('.active');
        otherTocElements.forEach(el => el.classList.remove('active'));
        tocElement.classList.add('active');
    }

    // root: null -> entire browser viewport
    const options = {
        root: null,
        rootMargin: '0px',
        threshold: 0.8
    };
    const observer = new IntersectionObserver(handleIntersection, options);

    headings.forEach(heading => {
        observer.observe(heading);
    });

    // Manually trigger the IntersectionObserver callback for the initial state
    const initialEntries = Array.from(headings).map(heading => ({
        isIntersecting: heading.getBoundingClientRect().top < window.innerHeight && heading.getBoundingClientRect().bottom > 0,
        target: heading
    }));
    handleIntersection(initialEntries);
});
document.addEventListener('DOMContentLoaded', function() {
    const nav_anchors = document.querySelectorAll('nav a');
    const contents_checkbox = document.getElementById('contents');
  
    nav_anchors.forEach(anchor => {
      anchor.addEventListener('click', function(event) {
        // Do not stop normal functionality of the anchor tag
        // event.preventDefault();
  
        // Uncheck the input with id "contents"
        if (contents_checkbox && contents_checkbox.type === 'checkbox') {
          contents_checkbox.checked = false;
        }
      });
    });
  });
  
document.addEventListener('DOMContentLoaded', () => {
  const headings = document.querySelectorAll('main h1[id], main h2[id], main h3[id], main h4[id], main h5[id], main h6[id]');

  headings.forEach(heading => {
    heading.addEventListener('click', event => {
      const target = event.target;

      if (target.tagName.toLowerCase().startsWith('h') && target.hasAttribute('id')) {
        const headingId = target.getAttribute('id');
        const url = new URL(window.location.href);
        url.hash = headingId;

        navigator.clipboard.writeText(url.toString())
          .then(() => {
            console.log('Heading URL copied to clipboard:', url.toString());
            target.classList.add('copy-success');
            target.setAttribute('title', 'Copied URL to clipboard! ✅');
            setTimeout(() => {
              target.classList.remove('copy-success');
              target.removeAttribute('title');
            }, 3000);

          })
          .catch(err => {
            console.error('Failed to copy the heading URL:', err);
            target.classList.add('copy-error');
            target.setAttribute('title', 'Failed to copy URL! ❌');
            setTimeout(() => {
              target.classList.remove('copy-error');
              target.removeAttribute('title');
            }, 3000);

          });
      }
    });
  });
});
</script>

</body>
</html>
