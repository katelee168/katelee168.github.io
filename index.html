<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Katherine Lee</title>
  <link rel="stylesheet" href="css/newspaper.css" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-165430430-1"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-165430430-1');
  </script>
</head>
<body>
  <div class="container">
    <nav class="navbar">
      <div class="nav-container">
        <div class="nav-brand">
          <a href="index.html">Katherine Lee</a>
        </div>
        <button class="nav-toggle" aria-label="Toggle navigation">
          <span class="hamburger"></span>
        </button>
        <ul class="nav-menu">
          <li class="nav-item">
            <a href="index.html#selected-publications" class="nav-link">Publications</a>
          </li>
          <li class="nav-item">
            <a href="index.html#writing" class="nav-link">Writing</a>
          </li>
          <li class="nav-item">
            <a href="index.html#invited-talks" class="nav-link">Talks</a>
          </li>
        </ul>
      </div>
    </nav>



    <main class="content">
            
            
      <article class="main-content">
                        <!-- <p align="left"><sup>(she/her)</sup></p>
                        <div><img style="padding: 25px" src="images/me.jpeg" width="200" border="50" align="right"/></div>
                        <div style="text-align: justify">Hello!  -->
                        <p><img class="avatar" alt="Katherine Lee" src="./images/katherine-300x300.jpg"></p>
                        <p>I am a researcher at OpenAI and run the <a
                        href="https://genlaw.org">GenLaw Center</a>. I
                        study security and privacy in generative AI
                        models and the legal implications those have.
                        Specifically, I evaluate data extraction
                        (memorization) in generative AI models and
                        attacks (mis-aligning) for generative AI
                        models.</p>
                        <p>Broadly, I’m interested in building machine
                        learning systems we can reliably use. This means
                        figuring out when models are brittle and
                        creating or discovering knobs to change their
                        behavior.</p>
                        <p>Previously, I worked at GDM (2023-2025) and
                        Google Brain (2017-2023). You can find me on the
                        internet: <a
                        href="https://scholar.google.com/citations?user=bjdB4K8AAAAJ&amp;hl=en">Google
                        Scholar</a>, <a
                        href="https://bsky.app/profile/katherinelee.bsky.social">Bluesky</a>,
                        and <a
                        href="https://www.goodreads.com/user/show/44386744-katherine">Goodreads</a>,
                        or email me at [my github handle] @
                        gmail.com</p>
                        <p>If you need a bio for a talk, please use this
                        one:</p>
                        <blockquote>
                        <p>Katherine is a researcher at OpenAI. Her work
                        has provided essential empirical evidence and
                        measurement for grounding discussions around
                        concerns that language models infringe
                        copyright, and about how language models can
                        respect an individuals’ right to privacy and
                        control of their data. Additionally, she has
                        developed large language models (T5), developed
                        methods of reducing memorization, and studied
                        the impact of data curation on model
                        development. Her work has been highly awarded at
                        venues like: NeurIPS, ICML, ICLR, and
                        USENIX.</p>
                        </blockquote>
                        <h2 id="selected-publications">Selected
                        Publications</h2>
                        <p>Full list on <a
                        href="https://scholar.google.com/citations?user=bjdB4K8AAAAJ&amp;hl=en">Google
                        Scholar</a></p>
                        <dl>
                        <dt>T5: Exploring the Limits of Transfer
                        Learning with a Unified Text-to-Text Transformer
                        [<a
                        href="https://www.jmlr.org/papers/volume21/20-074/20-074.pdf">JMLR</a>]<br/></dt>
                        <dd>
                        <a href="https://colinraffel.com/">Colin
                        Raffel</a>*, Noam Shazeer*, Adam Roberts*,
                        <strong>Katherine Lee</strong>*, Sharan Narang,
                        Michael Matena, Yanqi Zhou, Wei Li, Peter J.
                        Liu. June, 2020
                        </dd>
                        <dt>Extracting Training Data from Large Language
                        Models [<a
                        href="https://arxiv.org/abs/2012.07805">arxiv</a>]
                        [<a
                        href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting">USENIX
                        Oral</a>][<a
                        href="https://bair.berkeley.edu/blog/2020/12/20/lmmem/">blog</a>]
                        [<a
                        href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting">video</a>]<br/></dt>
                        <dd>
                        <a href="https://nicholas.carlini.com/">Nicholas
                        Carlini</a>, <a
                        href="https://floriantramer.com/">Florian
                        Tramèr</a>, <a
                        href="https://www.ericswallace.com/">Eric
                        Wallace</a>, <a
                        href="https://jagielski.github.io/">Matthew
                        Jagielski</a>, Ariel Herbert-Voss,
                        <strong>Katherine Lee</strong>, <a
                        href="https://research.google/people/104881/">Adam
                        Roberts</a>, Tom Brown, Dawn Song, Ulfar
                        Erlingsson, Alina Oprea, <a
                        href="https://colinraffel.com/">Colin
                        Raffel</a>. Dec, 2020
                        </dd>
                        <dd>
                        runner up <a
                        href="https://petsymposium.org/award/winners.php">Caspar
                        Bowden award at PETS 2023</a>
                        </dd>
                        <dt>Extracting Training Data from ChatGPT [<a
                        href="https://arxiv.org/abs/2311.17035">arxiv</a>][<a
                        href="https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html">blog</a>]<br/></dt>
                        <dd>
                        <a href="https://srxzr.com/">Milad Nasr*</a>, <a
                        href="https://nicholas.carlini.com/">Nicholas
                        Carlini*</a>, <a
                        href="https://jhayase.github.io/">Jon
                        Hayase</a>, <a
                        href="https://jagielski.github.io/">Matthew
                        Jagielski</a>, <a
                        href="https://afedercooper.info/">A. Feder
                        Cooper</a>, <a
                        href="https://daphnei.com/">Daphne Ippolito</a>,
                        <a
                        href="https://www.christopherchoquette.com/">Christopher
                        A. Choquette-Choo</a>, <a
                        href="https://ericswallace.com/">Eric
                        Wallace</a>, <a
                        href="https://www.floriantramer.com/">Florian
                        Tramèr</a>, <strong>Katherine Lee</strong>. Nov
                        2023
                        </dd>
                        <dt>Deduplicating Training Data Makes Language
                        Models Better [<a
                        href="https://arxiv.org/abs/2107.06499">arxiv</a>]
                        [<a
                        href="https://aclanthology.org/2022.acl-long.577/">ACL
                        Oral</a>]</dt>
                        <dd>
                        <strong>Katherine Lee</strong>*, <a
                        href="https://www.seas.upenn.edu/~daphnei/me/category/about-me.html">Daphne
                        Ippolito</a>*, Andrew Nystrom, <a
                        href="https://pluskid.org/">Chiyuan Zhang</a>,
                        <a
                        href="https://research.google/people/author39086/">Douglas
                        Eck</a>, <a
                        href="https://www.cis.upenn.edu/~ccb/">Chris
                        Callison-Burch</a>, <a
                        href="https://nicholas.carlini.com/">Nicholas
                        Carlini</a>. July 2021
                        </dd>
                        <dt>Quantifying Memorization Across Neural
                        Language Models [<a
                        href="https://arxiv.org/abs/2202.07646">arxiv</a>][ICLR
                        Spotlight]<br/></dt>
                        <dd>
                        <a href="https://nicholas.carlini.com/">Nicholas
                        Carlini</a>*, <a
                        href="https://www.seas.upenn.edu/~daphnei/me/category/about-me.html">Daphne
                        Ippolito</a>*, <a
                        href="https://jagielski.github.io/">Matthew
                        Jagielski</a>*, <strong>Katherine Lee*</strong>,
                        <a href="https://floriantramer.com/">Florian
                        Tramèr</a>*, <a
                        href="https://pluskid.org/">Chiyuan Zhang</a>*.
                        Feb 2022 (*authors alphabetical)
                        </dd>
                        <dt>What Does it Mean for a Language Model to
                        Preserve Privacy? [<a
                        href="https://arxiv.org/abs/2202.05520">arxiv</a>][<a
                        href="https://dl.acm.org/doi/fullHtml/10.1145/3531146.3534642">FAccT</a>]<br/></dt>
                        <dd>
                        Hannah Brown, <strong>Katherine Lee</strong>, <a
                        href="https://cseweb.ucsd.edu/~fmireshg/">Fatemehsadat
                        Mireshghalla</a>, <a
                        href="https://www.comp.nus.edu.sg/~reza/">Reza
                        Shokri</a>, <a
                        href="https://floriantramer.com/">Florian
                        Tramèr</a>. Feb 2022
                        </dd>
                        </dl>
                        <!-- Measuring Forgetting of Memorized Training Examples [[arxiv](https://arxiv.org/abs/2207.00099)][ICLR]<br/>: [Matthew Jagielski](https://jagielski.github.io/), [Om Thakkar](http://www.omthakkar.com/), [Florian Tramèr](https://floriantramer.com/), [Daphne Ippolito](https://www.seas.upenn.edu/~daphnei/me/category/about-me.html), **Katherine Lee**, [Nicholas Carlini](https://nicholas.carlini.com/), [Eric Wallace](https://www.ericswallace.com/), [Shuang Song](https://shs037.github.io/), Abhradeep Thakurta, [Nicolas Papernot](https://www.papernot.fr/), [Chiyuan Zhang](https://pluskid.org/). Jun 2022 -->
                        <!-- Counterfactual Memorization in Neural Language Models [[arxiv](https://arxiv.org/abs/2112.12938)]<br/>: [Chiyuan Zhang](https://pluskid.org/), [Daphne Ippolito](https://www.seas.upenn.edu/~daphnei/me/category/about-me.html), **Katherine Lee**, [Matthew Jagielski](https://jagielski.github.io/), [Florian Tramèr](https://floriantramer.com/), [Nicholas Carlini](https://nicholas.carlini.com/). December 2021 -->
                        <!-- WT5?! Training Text-to-Text Models to Explain their Predictions [[arxiv](https://arxiv.org/abs/2004.14546)]<br/>: Sharan Narang, [Colin Raffel](https://colinraffel.com/), **Katherine Lee**, Adam Roberts, Noah Fiedel, Karishma Malkan. April, 2020
                         -->
                        <dl>
                        <dt>Hallucinations in Neural Machine Translation
                        [<a
                        href="https://openreview.net/references/pdf?id=B1Muak8L4">NeurIPS
                        IRASL</a>] <br/></dt>
                        <dd>
                        <strong>Katherine Lee</strong>, Orhan Firat,
                        Ashish Agarwal, Clara Fannjiang, and David
                        Sussillo. Dec, 2018
                        </dd>
                        </dl>
                        <!-- Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification [[arxiv](https://arxiv.org/abs/2301.11562)][[pdf](https://katelee168.github.io/pdfs/arbitrary.pdf)]: [A. Feder Cooper](https://afedercooper.info/), **Katherine Lee**, Madiha Zahrah Choksi, Solon Barocas, Christopher De Sa, James Grimmelmann, Jon Kleinberg, Siddhartha Sen, Baobao Zhang. Jan, 2023 -->
                        <dl>
                        <dt>Talkin’ ’Bout AI Generation: Copyright and
                        the Generative-AI Supply Chain [<a
                        href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551">ssrn</a>]
                        [<a
                        href="https://arxiv.org/abs/2309.08133">arxiv</a>][<a
                        href="https://genlaw.org/explainers/talkin.html">blog</a>]<br/></dt>
                        <dd>
                        <strong>Katherine Lee</strong>*, <a
                        href="https://afedercooper.info/">A. Feder
                        Cooper</a>*, <a
                        href="http://james.grimmelmann.net/">James
                        Grimmelmann</a>*
                        </dd>
                        </dl>
                        <!-- Propagation of information along the cortical hierarchy as a function of attention while reading and listening to stories [[Cerebral Cortex](https://www.biorxiv.org/content/biorxiv/early/2018/04/08/291526.full.pdf)] <br/>: Mor Regev, Erez Simony, **Katherine Lee**, Kean Ming Tan, Janice Chen, Uri Hasson. Sep, 2019 -->
                        <h2 id="writing">Writing</h2>
                        <dl>
                        <dt><a href="https://genlaw.org/explainers/">AI
                        and Law: The Next Generation</a> (2023)</dt>
                        <dd>
                        <a
                        href="https://genlaw.org/explainers/training-data.html">The
                        Devil is in the Training Data</a> (2023)
                        </dd>
                        </dl>
                        <p><a
                        href="https://genlaw.org/explainers/talkin.html">Talkin’
                        ’Bout AI Generation: Copyright and the
                        Generative-AI Supply Chain</a> (2023)</p>
                        <p><a
                        href="https://craffel.github.io/blog/writing-a-google-ai-residency-cover-letter.html">Writing
                        a Google AI Residency Cover letter</a> with <a
                        href="https://ben-eysenbach.github.io/">Ben
                        Eysenbach</a> (2019)</p>
                        <p><a href="blog/submit-to-journals.html">Submit
                        to Journals</a> [<a
                        href="blog/submit-to-journals.pdf">pdf</a>]
                        (2018)</p>
                        <h3 id="fun-writing">Fun writing</h3>
                        <p><a href="blog/sourdough.html">Sourdough
                        Literature Review</a> (2020)</p>
                        <h2 id="invited-talks">Invited Talks</h2>
                        <dl>
                        <dt>Security</dt>
                        <dd>
                        Panel on Machine Learning, Memorization, and
                        Privacy at <a
                        href="https://tpdp.journalprivacyconfidentiality.org/2023/">Theory
                        and Practice of Differential Privacy (TPDP)</a>,
                        Sep 2023
                        </dd>
                        <dd>
                        <a href="https://www.prosus.com/">Prosus</a> AI
                        Marketplace, Oct 2023
                        </dd>
                        <dd>
                        Red Teaming Language Models at <a
                        href="https://www.cmu.edu/block-center/news-events/feb-23-kl-gates-event.html">Supporting
                        NIST’s Development of Guidelines on Red-teaming
                        for Generative AI</a>, Feb 2024 [<a
                        href="pdfs/red-teaming-feb-2024.pdf">slides</a>]
                        </dd>
                        <dd>
                        CHAI, Jul 2024
                        </dd>
                        <dt>Generative AI + Law</dt>
                        <dd>
                        Copyright Panel at <a
                        href="https://genlaw.org/">Generative AI + Law
                        Workshop @ ICML</a>, Jul 2023
                        </dd>
                        <dd>
                        The Copyright Law of Generative AI at <a
                        href="https://siliconflatirons.org/events/2023-10-06-generative-ai-and-copyright/">Silicon
                        Flatirons Generative AI and Copyright
                        Conference</a>, Oct 2023
                        </dd>
                        <dd>
                        Berkeley <a
                        href="https://www2.eecs.berkeley.edu/Courses/CS188/">CS
                        188.</a> Introduction to Artificial
                        Intelligence, Dec 2023
                        </dd>
                        <dd>
                        <a
                        href="https://computersciencelaw.org/2024-2/program/">CS
                        + Law</a>, Mar 2024
                        </dd>
                        <dd>
                        <a
                        href="https://www.law.berkeley.edu/research/bclt/bcltevents/btlj-bclt-spring2025/">28th
                        Annual BTLJ-BCLT Spring Symposium: AI Governance
                        at the Crossroads</a>, Feb 2025 [<a
                        href="https://bcle.law.berkeley.edu/program?id=85561">recording</a>]
                        </dd>
                        <dt>Memorization in Language Models [<a
                        href="https://katelee168.github.io/pdfs/privacy-slides-dec-2022.pdf">slides</a>]
                        [<a
                        href="https://katelee168.github.io/pdfs/aies-poster-2022.pdf">poster</a>][last
                        updated: Dec 2022]</dt>
                        <dd>
                        University of Toronto, May 2022
                        </dd>
                        <dd>
                        <a href="https://www.mosaicml.com/">Mosaic
                        ML</a>, Jul 2022
                        </dd>
                        <dd>
                        GovAI, Aug 2022
                        </dd>
                        <dd>
                        <a
                        href="https://vsehwag.github.io/SPML_seminar/">ML
                        Security &amp; Privacy Seminar</a>, Aug 2022
                        </dd>
                        <dd>
                        <a
                        href="https://www.legalityattentivedatascientists.eu/">LEgally
                        Attentive Data Scientists</a>, Sep 2022
                        </dd>
                        <dd>
                        Cornell, NLP Seminar, Sep 2022
                        </dd>
                        <dd>
                        <a href="https://c-psyd.github.io/">Cornell,
                        C-Psyd</a>, Sep, 2022
                        </dd>
                        <dt>Privacy</dt>
                        <dd>
                        Why do we care about privacy? at <a
                        href="https://ppai-workshop.github.io/">PPAI</a>,
                        Feb 2024 [<a
                        href="pdfs/why-privacy-feb-2024.pdf">slides</a>]
                        </dd>
                        <dd>
                        What does Privacy in Language Modeling Mean? [<a
                        href="https://katelee168.github.io/pdfs/lm-privacy-slides.pdf">slides</a>]
                        at UNC, Apr 2022
                        </dd>
                        <dd>
                        What does Privacy in Language Modeling Mean? [<a
                        href="https://katelee168.github.io/pdfs/lm-privacy-slides.pdf">slides</a>]
                        at Cornell, Apr 2022
                        </dd>
                        <dt>Dataset selection</dt>
                        <dd>
                        <a href="https://www.mosaicml.com/">Mosaic
                        ML</a>, Sep 2023
                        </dd>
                        <dt>Workshops</dt>
                        <dd>
                        Co-organized <a
                        href="https://www.genlaw.org/2024-icml">GenLaw
                        ICML 2024 Workshop</a>, Jul 2024
                        </dd>
                        <dd>
                        Co-organized Evaluating Generative AI Systems,
                        April 2024
                        </dd>
                        <dd>
                        Co-organized <a
                        href="https://blog.genlaw.org/2023-full-report.html">GenLaw
                        ICML 2023 Workshop</a> on Generative AI and Law,
                        Jul 2023 [<a
                        href="https://arxiv.org/abs/2311.06477">report</a>]
                        </dd>
                        </dl>
                        <!-- ## Service
                        * Organized the Generative AI and Law Workshop ([GenLaw '23'](https://genlaw.org/)) at ICML 2023.
                        * Helped organize [WELM workshop](https://welmworkshop.github.io/) at ICLR 2021 and moderated a panel discussion on "Bias, safety, copyright, and efficiency"
                        * Reviewer for NeurIPS, ICML. -->
                        <h2 id="fun">Fun!</h2>
                        <p>In my free time, I enjoy making stuff.
                        Sometimes this is <a
                        href="https://www.instagram.com/paw_projects/">pottery</a>,
                        <a
                        href="https://www.instagram.com/nomnomnom.s/">sourdough</a>,
                        or knitting/crocheting. I also enjoy being
                        outdoors, listening to <a
                        href="https://open.spotify.com/playlist/37i9dQZF1DX4wta20PHgwo?si=mkKIGDzISB61q_tBGndEiw">jazz</a>,
                        and dancing. Sometimes all at the same time! I
                        used to live <a
                        href="https://ludwigschubert.github.io/twotwelve.house/">here</a>.</p>
                        <p>During my undergrad in Operations Research at
                        Princeton, I had great fun learning about how
                        real neural networks (brains!) take in the world
                        with <a
                        href="https://pillowlab.princeton.edu/">Jonathan
                        Pillow</a> and <a
                        href="https://www.hassonlab.com/">Uri
                        Hasson</a>.</p>
                        <p>In the more distant past, I’ve also solved
                        for optimal seating arrangements at Google, and
                        I spotted ships at bay with hyperspectral
                        sensors at the Naval Research Lab in DC.</p>
      </article>
    </main>

    <footer class="footer">
      <div class="footer-content">
        <p>&copy; 2024 Katherine Lee. All rights reserved.</p>
        <p>Website generated with <a href="https://pandoc.org">Pandoc</a>, <a href="https://gist.github.com/killercup/5917178">pandoc.css</a>, and help from <a href="https://schubert.io/">Ludwig Schubert</a> and <a href="https://cursor.com">Cursor</a>.</p>
      </div>
    </footer>
  </div>


<script>
// Mobile navigation toggle
document.addEventListener('DOMContentLoaded', function() {
  const navToggle = document.querySelector('.nav-toggle');
  const navMenu = document.querySelector('.nav-menu');
  
  navToggle.addEventListener('click', function() {
    navMenu.classList.toggle('active');
    navToggle.classList.toggle('active');
  });
  
  // Close mobile menu when clicking on a link
  const navLinks = document.querySelectorAll('.nav-link');
  navLinks.forEach(link => {
    link.addEventListener('click', () => {
      navMenu.classList.remove('active');
      navToggle.classList.remove('active');
    });
  });
  
  // Close mobile menu when clicking outside
  document.addEventListener('click', function(event) {
    if (!navToggle.contains(event.target) && !navMenu.contains(event.target)) {
      navMenu.classList.remove('active');
      navToggle.classList.remove('active');
    }
  });
});
</script>
</body>
</html> 